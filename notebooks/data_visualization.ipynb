{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "# from tqdm import tqdm\n",
    "import medpy.metric as metric\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "import monai\n",
    "from monai.data import DataLoader, Dataset\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.transforms import BatchInverseTransform\n",
    "from monai.networks.nets import DynUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "seed = 0\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "monai.utils.misc.set_determinism(seed, use_deterministic_algorithms=True)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_kits_data(dataset_path: str = \"/dtu/3d-imaging-center/courses/02510/data/KiTS19\") -> list[dict]:\n",
    "    \"\"\" Assumes the data has quite specific structure. \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'image': str(path),                                                         # the unlabeled volume file, 'imaging.nii.gz'\n",
    "            'label': str(path).replace(\"imaging.nii.gz\", \"segmentation_kidney.nii.gz\"), # all the labeled data is named 'segmentation_kidney.nii.gz'\n",
    "            'id': path.parent.name                                                      # the dir name, e.g. 'case_00000'\n",
    "        }\n",
    "        for path in sorted(Path(dataset_path).glob(\"*/imaging.nii.gz\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_acd_data(dataset_path: str = \"/dtu/3d-imaging-center/courses/02510/data/ACDC17\") -> list[dict]:\n",
    "    \"\"\" Assumes the data is in patient00X folders etc. \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'image': str(path),                                 # the unlabeled volume file\n",
    "            'label': str(path).replace(\".nii.gz\", \"_gt.nii.gz\"),# all the labeled data has _gt in the path\n",
    "            'id': path.name.split(\".\")[0]                       # the file name without ending \n",
    "        }\n",
    "        for path in sorted(Path(dataset_path).glob(\"*/*frame[0-9][0-9].nii.gz\"))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': '/dtu/3d-imaging-center/courses/02510/data/KiTS19/case_00000/imaging.nii.gz', 'label': '/dtu/3d-imaging-center/courses/02510/data/KiTS19/case_00000/segmentation_kidney.nii.gz', 'id': 'case_00000'}\n"
     ]
    }
   ],
   "source": [
    "all_files = read_kits_data()\n",
    "print(all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = nib.load(all_files[0]['image'])\n",
    "label = nib.load(all_files[0]['label'])\n",
    "name = all_files[0]['id']\n",
    "\n",
    "x, y, z = im.shape[0] // 2, im.shape[1] // 2, im.shape[2] // 2\n",
    "\n",
    "plot = nib.viewers.OrthoSlicer3D(label.get_fdata(), title=\"Center slice of MRI data\")\n",
    "plot.set_position(x,y,z)\n",
    "plt.tight_layout()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Get the (new) voxel size\n",
    "# voxel_sizes = np.array([nib.load(file['image']).header.get_zooms() for file in all_files])\n",
    "voxel_dims = 1.464845, 1.464845, 10.0 # np.median(voxel_sizes, axis=0)\n",
    "\n",
    "n_classes = 2\n",
    "im_dims = 256, 256,-1 #TODO: Should be defined further up\n",
    "batch_size = 4 # TODO: Batch size >= 1 doesnt work for some reason\n",
    "\n",
    "transforms = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImaged(keys=['image', 'label']),\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['image', 'label']),\n",
    "    monai.transforms.Spacingd(keys=['image', 'label'], pixdim=voxel_dims, mode=[\"bilinear\", \"nearest\"]),\n",
    "    monai.transforms.ResizeWithPadOrCropd(keys=['image', 'label'], spatial_size=im_dims),\n",
    "    monai.transforms.RandSpatialCropd(keys=['image', 'label'], roi_size=[-1, -1, 1]),\n",
    "    # monai.transforms.SqueezeDimd(keys=['image', 'label'], dim=-1), # TODO: This doesn't work for some reason\n",
    "\n",
    "    # TODO: (Light) data augmentation\n",
    "\n",
    "    # monai.transforms.AsDiscreted(keys=['label'], to_onehot=n_classes) # Convert \"label\" to onehot encoded.\n",
    "])\n",
    "\n",
    "full_dataset = Dataset(data=all_files, transform=transforms)\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, lengths = [0.7, 0.1, 0.2])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader   = DataLoader(val_dataset, batch_size=1, shuffle=False) \n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=1, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num params: 20_611_170\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model): \n",
    "    \"\"\" Get the number of params in a model. See: https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325\"\"\"\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = DynUNet(\n",
    "    spatial_dims = 2,   # 2 for 2D convolutions, 3 for 3D convolutions\n",
    "    in_channels  = 1,   # Number of input channels/modalities (3 for RGB)\n",
    "    out_channels = n_classes,   # Number of classes, including background\n",
    "    kernel_size  = [3, 3, 3, 3, 3, 3], # Size of the filters\n",
    "    strides      = [1, 2, 2, 2, 2, 2],\n",
    "    upsample_kernel_size = [2, 2, 2, 2, 2]\n",
    ").to(device)\n",
    "\n",
    "print(f\"Num params: {count_parameters(model):_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n",
      "metatensor(13.6934)\n",
      "0.004202576362030636\n"
     ]
    }
   ],
   "source": [
    "loss_fn = monai.losses.DiceLoss(softmax=True, to_onehot_y=False) # Apply \"softmax\" to the output of the network and don't convert to onehot because this is done already by the transforms.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "inferer = monai.inferers.SliceInferer(roi_size=[-1, -1], spatial_dim=2, sw_batch_size=1)\n",
    "\n",
    "with torch.no_grad():  # Do not need gradients for this part\n",
    "    for batch in val_dataloader:\n",
    "        x = batch['image'].to(device).squeeze(dim = -1) # TODO: This squeeze has to be here because monai.transforms.SqueezeDimd gives error\n",
    "        y = batch['label'].to(device).squeeze(dim = -1) # TODO: This squeeze has to be here because monai.transforms.SqueezeDimd gives error\n",
    "        \n",
    "        print(x.shape, y.shape)\n",
    "        pred = model(x)\n",
    "        print(pred.shape)\n",
    "        # print(pred.shape)\n",
    "        # prediction = inferer(inputs=x, network=model)\n",
    "        print(pred.max())\n",
    "        # print(metric.dc(pred.argmax(dim=1), y))\n",
    "        print(metric.dc(torch.ones_like(y), y))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NJKNASJKD\n"
     ]
    }
   ],
   "source": [
    "if torch.count_nonzero(torch.ones(1, 2, 256, 256, dtype=torch.int32)):\n",
    "    print(\"NJKNASJKD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The first supplied array does not contain any binary object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch.Size([1, 2, 256, 256]) torch.Size([1, 2, 256, 256])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhd95\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/deeplearning3d/2d-to-3d-transfer-learning/.env/lib/python3.10/site-packages/medpy/metric/binary.py:413\u001b[0m, in \u001b[0;36mhd95\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhd95\u001b[39m(result, reference, voxelspacing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, connectivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    372\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    95th percentile of the Hausdorff Distance.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;124;03m    This is a real metric. The binary images can therefore be supplied in any order.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 413\u001b[0m     hd1 \u001b[38;5;241m=\u001b[39m \u001b[43m__surface_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoxelspacing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconnectivity\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     hd2 \u001b[38;5;241m=\u001b[39m __surface_distances(reference, result, voxelspacing, connectivity)\n\u001b[1;32m    415\u001b[0m     hd95 \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mpercentile(numpy\u001b[38;5;241m.\u001b[39mhstack((hd1, hd2)), \u001b[38;5;241m95\u001b[39m)\n",
      "File \u001b[0;32m~/deeplearning3d/2d-to-3d-transfer-learning/.env/lib/python3.10/site-packages/medpy/metric/binary.py:1265\u001b[0m, in \u001b[0;36m__surface_distances\u001b[0;34m(result, reference, voxelspacing, connectivity)\u001b[0m\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;66;03m# test for emptiness\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m==\u001b[39m numpy\u001b[38;5;241m.\u001b[39mcount_nonzero(result):\n\u001b[0;32m-> 1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1266\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe first supplied array does not contain any binary object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1267\u001b[0m     )\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m==\u001b[39m numpy\u001b[38;5;241m.\u001b[39mcount_nonzero(reference):\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe second supplied array does not contain any binary object.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The first supplied array does not contain any binary object."
     ]
    }
   ],
   "source": [
    "# torch.Size([1, 2, 256, 256]) torch.Size([1, 2, 256, 256])\n",
    "metric.binary.hd95(torch.zeros(1, 2, 256, 256, dtype=torch.int32).numpy(), torch.ones(1, 2, 256, 256, dtype=torch.int32).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Epoch 1/3 ****\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 256, 256, 28]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[194], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 24\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[1;32m     27\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/monai/networks/nets/dynunet.py:269\u001b[0m, in \u001b[0;36mDynUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 269\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mskip_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_block(out)\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeep_supervision:\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/monai/networks/nets/dynunet.py:47\u001b[0m, in \u001b[0;36mDynUNetSkipLayer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 47\u001b[0m     downout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     nextout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_layer(downout)\n\u001b[1;32m     49\u001b[0m     upout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsample(nextout, downout)\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/monai/networks/blocks/dynunet_block.py:171\u001b[0m, in \u001b[0;36mUnetBasicBlock.forward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inp):\n\u001b[0;32m--> 171\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(out)\n\u001b[1;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlrelu(out)\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/monai/data/meta_tensor.py:282\u001b[0m, in \u001b[0;36mMetaTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 282\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# if `out` has been used as argument, metadata is not copied, nothing to do.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;66;03m# if \"out\" in kwargs:\u001b[39;00m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;66;03m#     return ret\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _not_requiring_metadata(ret):\n",
      "File \u001b[0;32m/dtu/3d-imaging-center/courses/conda/miniconda3/envs/env-02510/lib/python3.11/site-packages/torch/_tensor.py:1386\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1386\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [1, 1, 256, 256, 28]"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "n_epochs = 3\n",
    "\n",
    "loss_fn = monai.losses.DiceLoss(softmax=True, to_onehot_y=False) # Apply \"softmax\" to the output of the network and don't convert to onehot because this is done already by the transforms.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "inferer = monai.inferers.SliceInferer(roi_size=[-1, -1], spatial_dim=2, sw_batch_size=1)\n",
    "\n",
    "iterations = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"**** Epoch {epoch+1}/{n_epochs} ****\")\n",
    "\n",
    "    training_loss = 0.0\n",
    "    validation_loss = 0.0\n",
    "\n",
    "    # Train\n",
    "    model.train()\n",
    "    for batch_num, batch in enumerate(train_dataloader):\n",
    "        x = batch['image'].to(device)\n",
    "        y = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        training_loss += loss\n",
    "\n",
    "        if (iterations % config.wandb.train_log_interval == config.wandb.train_log_interval - 1):\n",
    "            print(f\"{batch_num + 1}/{len(train_dataloader)} | loss: {loss:.3f}\")\n",
    "            wandb.log({\n",
    "                \"epoch\" : epoch,\n",
    "                \"iteration\" : iterations,\n",
    "                \"batch/train\" : batch_num,\n",
    "                \"loss/train\"  : training_loss.item() / (batch_num + 1),\n",
    "            })\n",
    "        \n",
    "        iterations += 1\n",
    "\n",
    "\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_num, batch in enumerate(val_dataloader):\n",
    "            x = batch['image'].to(device)\n",
    "            y = batch['label'].to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            validation_loss += loss\n",
    "\n",
    "            if (batch_num % config.wandb.validation_log_interval == config.wandb.validation_log_interval - 1):\n",
    "                print(f\"{batch_num + 1}/{len(val_dataloader)} | val loss: {loss.item():.3f}\")\n",
    "                wandb.log({\n",
    "                    \"epoch\" : epoch,\n",
    "                    \"batch/val\" : batch_num,\n",
    "                    \"loss/val\": validation_loss.item() / (batch_num + 1),\n",
    "                })\n",
    "\n",
    "\n",
    "    \n",
    "    # Logging\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imageDims = np.array([nib.load(file['image']).header.get_data_shape() for file in all_files])\n",
    "\n",
    "print(np.median(imageDims[:,2]))\n",
    "\n",
    "plt.hist(imageDims[:,2])\n",
    "plt.title(\"Size of 3rd dim of KiTS data (256, 256, x)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
